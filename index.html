<!DOCTYPE html>
<html lang="en">

</html>
<html>

<head>
    <base href="/">
    <title>Page Title</title>
    <style type="text/css">
        .strip {
            padding: 2rem;
        }

        .strip img {
            width: 100px;
            overflow-x: scroll;
            padding: 0.8rem 0.8rem 2.5rem 0.8rem;
            box-shadow: 0 0 3px rgba(0, 0, 0, 0.2);
            background: white;
        }
    </style>

</head>


<body>
    <script type="text/javascript" src="https://rawgit.com/131/h264-live-player/master/vendor/dist/http-live-player.js"></script>
    <script src="./dist/bundle.js" charset="uft-8"></script>
    <script src="./StreamToCanvas2D.js" charset="uft-8"></script>
    <script>
        //Receiving <canvas> for H264(Rasberry PI Format) only loaded in memoy
        const canvas = document.createElement("canvas");
        const video = document.createElement("video");
        let canvasD = document.createElement("canvas");
        let ctxD = canvasD.getContext('2d');
        const pellicule = document.createElement("div")
        document.body.appendChild(canvasD).setAttribute("id", "destination");
        document.body.appendChild(pellicule).setAttribute("class", "strip");



        // Streaming to Canvas from Raspberry PI with Express Socket
        // <canvas> WEBGL(H264)
        const wsavc = new WSAvcPlayer(canvas, "webgl");
        const protocol = window.location.protocol === "http:" ? "ws:" : "ws:"
        wsavc.connect(protocol + '//' + window.location.host + '/video-stream');

        //Streaming to <video>(captureStream)

        const stream = canvas.captureStream();
        video.srcObject = stream;
        video.play()

        //Streaming to <canvas> ctx 2D
        //Pixelisation Size
        var sample_size = 10
        // make an array to hold our old pixel values
        var previous_frame = [];
        // choose a brightness threshold, if the old pixel values differs enough then we know there's movement
        var threshold = 15;
        var alert = 0



        function takePhoto() {

            //take the data out of the canvas.
            const strip = document.querySelector('.strip');
            const data = canvas.toDataURL('image/jpeg');
            const link = document.createElement('a');
            link.href = data;
            link.setAttribute('download', 'handsome');
            link.innerHTML = `<img src="${data}" alt="AI Picture" />`;
            // Sending image to Watson


            const stringImage = data;
            //const imgFile = new Base64Decode(stringImage);
            console.log(stringImage)

            strip.insertBefore(link, strip.firstElementChild);

        }
        video.addEventListener('progress', StreamToCanvas2D);
    </script>
</body>

</html>